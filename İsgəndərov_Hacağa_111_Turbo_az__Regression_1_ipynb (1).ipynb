{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download sehriyarmemmedli/turboaz-cars-project\n",
        "!unzip turboaz-cars-project.zip"
      ],
      "metadata": {
        "id": "rj9v1iG14NkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Cleaning"
      ],
      "metadata": {
        "id": "r5pZUqXEubdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Data Yükləmə\n",
        "df = pd.read_csv('/content/cars.csv')\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# DataFrame-də ilkin yoxlama\n",
        "df.head()\n",
        "df.shape\n",
        "\n",
        "# Sütun adlarının transformasiyası\n",
        "df.columns = df.columns.str.strip().str.replace(r'\\s+', '_', regex=True).str.lower()\n",
        "\n",
        "# DataFrame-dəki dəyərlərin transformasiyası\n",
        "df = df.map(lambda x: x.strip().replace(' ', '_').lower() if isinstance(x, str) else x)\n",
        "\n",
        "# Dublikatları silirik\n",
        "df = df.drop_duplicates(subset=['car_rel_url_x'], keep='last')\n",
        "\n",
        "# Silinəcək sütunlar\n",
        "silineceq_sutunlar_1 = ['id_x', 'car_rel_url_x', 'img_url', 'id_y', 'cars_id', 'car_rel_url_y',\n",
        "                        'phone', 'car_details_id_x', 'car_rel_url', 'car_details_id_y', 'datetime_scrape',\n",
        "                        'name', 'datetime_product', 'attributes', 'datetime', 'views', 'price_x',\n",
        "                        'currency_x', 'production_year', 'city', 'yürüş', 'hour', 'day', 'updated',\n",
        "                        'extra_info', 'vin', 'owner_name', 'shop_name', 'engine_displacement_unit',\n",
        "                        'kilometrage_unit', 'marka','description', 'vəziyyəti']\n",
        "\n",
        "# Sütunları silirik\n",
        "df.drop(columns=silineceq_sutunlar_1, inplace=True)\n",
        "\n",
        "# Numeric olan sütunları seçmək\n",
        "numeric_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# 97%-dan böyük olan dəyərləri tapmaq\n",
        "percentile_97 = np.percentile(df['kilometrage_num'], 97.)\n",
        "\n",
        "# 97%-dan böyük olan dəyərləri tapıb 97%-ın qiymətinə bərabər edirik\n",
        "df['kilometrage_num'] = np.where(df['kilometrage_num'] > percentile_97, percentile_97, df['kilometrage_num'])\n",
        "\n",
        "# Buraxılış ili üzrə aşağı 1%-ı təyin edirik\n",
        "percentile_1 = np.percentile(df['buraxılış_ili'], 1)\n",
        "df['buraxılış_ili'] = np.where(df['buraxılış_ili'] < percentile_1, percentile_1, df['buraxılış_ili'])\n",
        "\n",
        "# Şəhər sütununu təmizləmək\n",
        "df['şəhər'] = df['şəhər'].apply(lambda x: 'bakı' if x == 'bakı' else 'digər')\n",
        "\n",
        "# Standart olmayan ifadələri uyğun terminlərlə əvəz etmək üçün xəritə\n",
        "standart_xerite = {\n",
        "    'hetçbek 3 qapı': 'hatchback',\n",
        "    'hetçbek 4 qapı': 'hatchback',\n",
        "    'hetçbek 5 qapı': 'hatchback',\n",
        "    'offroader suv 3 qapı': 'suv',\n",
        "    'offroader suv 5 qapı': 'suv',\n",
        "    'offroader suv açıq': 'suv',\n",
        "    'pikap ikiqat kabin': 'pickup',\n",
        "    'pikap tək kabin': 'pickup',\n",
        "    'pikap bir yarım kabin': 'pickup',\n",
        "    'universal 3 qapı': 'wagon',\n",
        "    'universal 5 qapı': 'wagon',\n",
        "    'suv kupe': 'suv coupe',\n",
        "    'mikroavtobus': 'microbus',\n",
        "    'mikrovan': 'microvan',\n",
        "    'yük maşını': 'truck',\n",
        "    'furqon': 'van',\n",
        "    'karvan': 'caravan',\n",
        "    'fayton': 'carriage',\n",
        "    'qolfkar': 'golf cart',\n",
        "    'spidster': 'speedster',\n",
        "    'tarqa': 'targa'\n",
        "}\n",
        "\n",
        "# Təmizləmə funksiyası\n",
        "def temizle_ban_novu(text):\n",
        "    if pd.isna(text):\n",
        "        return text\n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r'[_/,]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return standart_xerite.get(text, text)\n",
        "\n",
        "# Ban növünü təmizləmək\n",
        "df['ban_növü'] = df['ban_növü'].apply(temizle_ban_novu)\n",
        "\n",
        "# Yeni sütunlar yaradaraq mühərrik gücünü çıxarmaq\n",
        "df['güc'] = df['mühərrik'].str.extract(r'(\\d+)_a\\.g\\.')\n",
        "df['güc'] = pd.to_numeric(df['güc'], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "# Yanacaq növü üçün yeni sütun\n",
        "df['yanacaq_növü'] = df['mühərrik'].str.split('/').str[-1].str.replace('_', '')\n",
        "df['yanacaq_növü'] = df['yanacaq_növü'].replace({\n",
        "    'dizel': 'dizel',\n",
        "    'benzin': 'benzin',\n",
        "    'elektro': 'elektro',\n",
        "    'hibrid': 'hibrid',\n",
        "    'pluginhibrid': 'plug-in hibrid',\n",
        "    'qaz': 'qaz',\n",
        "    'hidrogen': 'hidrogen'\n",
        "})\n",
        "\n",
        "# 'mühərrik' sütununu silirik\n",
        "df.drop(columns=['mühərrik'], inplace=True)\n",
        "\n",
        "# Target dəyişənini hazırlayırıq (price_azn)\n",
        "exchange_rates = {'usd': 1.7, 'eur': 1.67, 'azn': 1}\n",
        "df['price_azn'] = df['price_y'] * df['currency_y'].map(exchange_rates)\n",
        "\n",
        "# 'price_y' və 'currency_y' sütunlarını silirik\n",
        "df.drop(columns=['price_y', 'currency_y'], inplace=True)\n",
        "\n",
        "# Hazırkı ili alırıq və yaş hesablayırıq\n",
        "current_year = datetime.datetime.now().year\n",
        "df['yaş'] = current_year - df['buraxılış_ili']\n",
        "\n",
        "df.drop(columns=['buraxılış_ili'], inplace=True)\n",
        "\n",
        "# Numeric dəyişənləri yenidən yoxlayaq\n",
        "df['annual_mileage'] = df['kilometrage_num'] / df['yaş']\n",
        "df['power_to_displacement'] = df['güc'] / df['engine_displacement_num']\n",
        "\n",
        "df['annual_mileage'].fillna(df['annual_mileage'].median(), inplace=True)\n",
        "df['power_to_displacement'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df['power_to_displacement'].fillna(df['power_to_displacement'].median(), inplace=True)\n",
        "\n",
        "# Kategorik dəyişənləri təmizləyirik\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "df[categorical_cols] = df[categorical_cols].fillna('missing')\n",
        "\n",
        "# Bəzi dəyişənləri daha sadə və optimallaşdırılmış formada saxlayırıq\n",
        "top_6_colors = df['rəng'].value_counts().head(6).index\n",
        "df['rəng'] = df['rəng'].apply(lambda x: x if x in top_6_colors else 'digər')\n",
        "\n",
        "top_2_gearboxes = df['sürətlər_qutusu'].value_counts().head(2).index\n",
        "df['sürətlər_qutusu'] = df['sürətlər_qutusu'].apply(lambda x: x if x in top_2_gearboxes else 'digər')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6x1Qc7VWSMnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "pDM6wL454Mv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "WmJOTDclN0qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "qC5wc2T3N36Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "LNdvRmc9N7w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vizualizasiya"
      ],
      "metadata": {
        "id": "VFRG8LgwtP5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Objekt tipli sütunları seçirik\n",
        "object_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# 2-dən çox kateqoriyası olan sütunları filtrləyirik\n",
        "for col in object_columns:\n",
        "    if df[col].nunique() > 2:  # 2-dən çox unikal kateqoriya varsa\n",
        "        # Kateqoriyaların paylanması\n",
        "        category_counts = df[col].value_counts()\n",
        "\n",
        "        # Bar plot ilə paylanmanı göstəririk\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.barplot(x=category_counts.index, y=category_counts.values, palette='viridis')\n",
        "        plt.title(f\"'{col}' sütunundakı kateqoriyaların paylanması\", fontsize=14)\n",
        "        plt.xlabel('Kateqoriyalar', fontsize=12)\n",
        "        plt.ylabel('Say', fontsize=12)\n",
        "        plt.xticks(rotation=45, ha='right')  # X oxunu döndəririk\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "apmfErt6tPpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kiçik bir alt dataset seçirik (10000 sətir)\n",
        "sample_df = df.sample(n=50000, random_state=42)"
      ],
      "metadata": {
        "id": "OX7lxfZhW-Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lasso Model"
      ],
      "metadata": {
        "id": "Ib4wicta4MNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAE və R²-nin birgə istifadəsi:\n",
        "Həm MAE (həqiqi səhvləri) həm də R² (modelin uyğunluğunu) izləyərək, modelin həm nəticə səhvlərini, həm də yaxşılığını qiymətləndirmək mümkündür. Birlikdə istifadə olunanda bu iki metrik:\n",
        "\n",
        "MAE modelin nə qədər dəqiq olduğunu göstərir,\n",
        "R² isə modelin məlumatlardakı dəyişkənliyi nə qədər yaxşı izah etdiyini göstərir.\n",
        "Beləliklə, bu iki metrik həm modelin ümumi keyfiyyətini, həm də proqnozların nə qədər doğru olduğunu daha ətraflı şəkildə qiymətləndirməyə kömək edir"
      ],
      "metadata": {
        "id": "EBfECWTouwCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Niyə Lasso model secdim.\n",
        "\n",
        "Təkrarlanan və ya əhəmiyyətsiz xüsusiyyətləri kənara qoymaq: Lasso modelində, cərimə tətbiq edildikcə, əhəmiyyətsiz xüsusiyyətlər sıfırlanır. Bu, xüsusiyyətlərin səmərəli seçilməsini və modelin sadələşdirilməsini təmin edir.\n",
        "\n",
        "Daha az overfitting riski: Lasso'nun cərimə tətbiq etməsi, overfitting (çox yaxşı təlim məlumatlarına uyğunlaşma) riskini azaldır. Bu, xüsusən çox sayda xüsusiyyətə sahib datasetlərdə vacibdir.\n"
      ],
      "metadata": {
        "id": "0rRYWVIguxIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lazım olan kitabxanaları idxal edirik\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "from scipy.stats import uniform\n",
        "\n",
        "\n",
        "# X və y-nin ayrılması\n",
        "X = sample_df.drop(columns='price_azn')  # Target variable\n",
        "y = sample_df['price_azn']  # Target variable\n",
        "\n",
        "# Verilənləri train və test hissələrinə ayırırıq\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Kateqorial və sayısal dəyişənləri ayırırıq\n",
        "numerical_cols = ['engine_displacement_num', 'kilometrage_num', 'güc', 'yaş', 'annual_mileage', 'power_to_displacement']\n",
        "categorical_cols = ['barter', 'loan', 'salon', 'spare_parts', 'vip', 'featured', 'ban_növü',\n",
        "                    'hansı_bazar_üçün_yığılıb', 'model', 'qəzalı', 'rəng', 'sahiblər', 'sürətlər_qutusu',\n",
        "                    'yeni', 'yerlərin_sayı', 'ötürücü', 'şəhər', 'yanacaq_növü']\n",
        "\n",
        "# Sayısal və kateqorial verilənlər üçün fərqli transformasiya addımları\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Missing dəyərləri orta ilə əvəz edirik\n",
        "    ('scaler', StandardScaler()),  # Miqyaslama\n",
        "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Polynomial Features\n",
        "    ('pca', PCA(n_components=5))  # PCA ilə ölçü azaldılması\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Missing dəyərləri ən çox təkrarlanan dəyərlə əvəz edirik\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-Hot Encoding\n",
        "])\n",
        "\n",
        "# Hər iki tip dəyişən üçün transformasiyaları birləşdiririk\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Model və preprocessing addımlarını birləşdiririk\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', Lasso(random_state=42))  # Lasso regression modelini istifadə edirik\n",
        "])\n",
        "\n",
        "# Modeli fit edirik\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Test datası ilə modelin qiymətləndirilməsi\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "\n",
        "# Performans metrikləri\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"R²: {r2}\")\n",
        "print(f\"RMSE: {rmse}\")\n",
        "\n",
        "# Kross-validasiya ilə daha yaxşı qiymətləndirmə\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(model_pipeline, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
        "\n",
        "print(f\"5-fold CV Mean RMSE: {np.sqrt(-cv_scores.mean())}\")\n",
        "\n",
        "\n",
        "# Hyperparameter tuning (RandomizedSearchCV ilə)\n",
        "param_dist = {\n",
        "    'regressor__alpha': uniform(0.01, 10),  # Alpha parametri 0.01 ilə 10 arasında for Lasso\n",
        "    'regressor__max_iter': [1000, 2000, 5000, 10000],  # Iterasiya sayını dəyişirik for Lasso\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV ilə hyperparameter tuning\n",
        "random_search = RandomizedSearchCV(Lasso, param_distributions=param_dist, n_iter=10, cv=5,\n",
        "                                   n_jobs=-1, scoring='neg_mean_squared_error', random_state=42)\n",
        "random_search = RandomizedSearchCV(model_pipeline, param_distributions=param_dist, n_iter=10, cv=kf,\n",
        "                                   n_jobs=-1, scoring='neg_mean_squared_error', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "print(f\"Best CV RMSE: {np.sqrt(-random_search.best_score_)}\")\n"
      ],
      "metadata": {
        "id": "3lXmH64L4MKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RandomForestRegressor"
      ],
      "metadata": {
        "id": "NwIYziCX4MCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomForestRegressor niyə seçdim.\n",
        "\n",
        "Yüksək performanslı və çox yönlüdür: Random Forest, çox sayda qərar ağacından ibarət bir ensemble (topluluk) modelidir və ümumilikdə yaxşı nəticələr verir. Bu model həm sayısal həm də kateqorial verilənlər üzərində yüksək performans göstərə bilir."
      ],
      "metadata": {
        "id": "TclTjSsqwo6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Lazım olan kitabxanaları idxal edirik\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# X və y-nin ayrılması\n",
        "X = sample_df.drop(columns='price_azn')  # Target variable\n",
        "y = sample_df['price_azn']  # Target variable\n",
        "\n",
        "# Verilənləri train və test hissələrinə ayırırıq\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Kateqorial və sayısal dəyişənləri ayırırıq\n",
        "numerical_cols = ['engine_displacement_num', 'kilometrage_num', 'güc', 'yaş', 'annual_mileage', 'power_to_displacement']\n",
        "categorical_cols = ['barter', 'loan', 'salon', 'spare_parts', 'vip', 'featured', 'ban_növü',\n",
        "                    'hansı_bazar_üçün_yığılıb', 'model', 'qəzalı', 'rəng', 'sahiblər', 'sürətlər_qutusu',\n",
        "                    'yeni', 'yerlərin_sayı', 'ötürücü', 'şəhər', 'yanacaq_növü']\n",
        "\n",
        "# Sayısal və kateqorial verilənlər üçün fərqli transformasiya addımları\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Missing dəyərləri orta ilə əvəz edirik\n",
        "    ('scaler', StandardScaler()),  # Miqyaslama\n",
        "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Polynomial Features\n",
        "    ('pca', PCA(n_components=5))  # PCA ilə ölçü azaldılması\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Missing dəyərləri ən çox təkrarlanan dəyərlə əvəz edirik\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-Hot Encoding\n",
        "])\n",
        "\n",
        "# Hər iki tip dəyişən üçün transformasiyaları birləşdiririk\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Model və preprocessing addımlarını birləşdiririk\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(random_state=42))  # Random Forest Regressor istifadə edirik\n",
        "])\n",
        "\n",
        "# Modeli fit edirik\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Test datası ilə modelin qiymətləndirilməsi\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "\n",
        "# Performans metrikləri\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"R²: {r2}\")\n",
        "print(f\"RMSE: {rmse}\")\n",
        "\n",
        "# Kross-validasiya ilə daha yaxşı qiymətləndirmə\n",
        "cv_scores = cross_val_score(model_pipeline, X, y, cv=3, scoring='neg_mean_squared_error')\n",
        "\n",
        "print(f\"3-fold CV Mean RMSE: {np.sqrt(-cv_scores.mean())}\")\n",
        "\n",
        "\n",
        "# Hyperparameter tuning (RandomizedSearchCV ilə)\n",
        "param_dist = {\n",
        "    'regressor__n_estimators': [100, 200, 500],  # Random Forest üçün ağac sayını dəyişirik\n",
        "    'regressor__max_depth': [None, 10, 20, 30],  # Random Forest ağaclarının maksimum dərinliyini dəyişirik\n",
        "    'regressor__min_samples_split': [2, 5, 10],  # Ağacın bölünməsini minimum nümunə sayını dəyişirik\n",
        "    'regressor__min_samples_leaf': [1, 2, 4],  # Ağacın yarpağında minimum nümunə sayını dəyişirik\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(model_pipeline, param_distributions=param_dist, n_iter=10, cv=3,\n",
        "                                   n_jobs=-1, scoring='neg_mean_squared_error', random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "print(f\"Best CV RMSE: {np.sqrt(-random_search.best_score_)}\")\n"
      ],
      "metadata": {
        "id": "iEIkCrI7bsiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "R²: 0.728, modelin təxminlərinin hədəf dəyişkənlə nə qədər yaxşı uyğunlaşdığını göstərir. Əvvəlki nəticədə bu dəyər 0.36 idi, yəni əvvəlki model çox zəif təxminlər vermişdi.\n",
        "RMSE: 13527.22, modelin səhvlərinin ölçüsünü göstərir. Bu da əvvəlki 20745.60-dan daha aşağıdır, yəni modelin səhvləri kiçilib.\n",
        "CV Mean RMSE: 13711.80, 3-fold cross-validation ilə əldə edilən orta RMSE qiymətidir. Bu da modelin ümumi performansını yaxşılaşdırmağa kömək edən bir metrikdir."
      ],
      "metadata": {
        "id": "eqRmXP-d0FFM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eDaaMMv40F0i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}